from sys import float_repr_style
from batchflow.core.node import ProcessorNode
import keras
from typing import Any, Dict, List
import numpy as np
from batchflow.decorators import log_time
from sklearn import model_selection
import mediapipe as mp
import math


class BlazeFace(ProcessorNode):
    def __init__(
        self,
        threshold: float_repr_style = 0.9,
        alignface=True,
        no_detection=None,
        model_selection=1,
        *args,
        **kwargs,
    ) -> None:
        """
        Initalise RetinaFace Detector
        model and code taken from https://github.com/serengil/retinaface


        Args:
            model_path (str, optional): [path to model weights file]. Defaults to None.
            model_source (Dict[str, str], optional): [cloud storage ref to download the model to BATCHFLOW_HOME dir,
            refer available model_source option <>].
            Defaults to {
                source: gdrive,
                id: 1ALrrsY54fAdnmB4Zgp7yXw1-xjekiiMO,
                filename: retinaface.h5
            }
            threshold (float): face detection confidence threshold, Defaults to 0.9
        """
        super().__init__(*args, **kwargs)
        self.mp_face_detection = mp.solutions.face_detection
        self.mp_drawing = mp.solutions.drawing_utils
        self.threshold = threshold
        self.model_selection = model_selection
        self.no_detection = no_detection

    def open(self):

        self.model = self.mp_face_detection.FaceDetection(
            model_selection=1, min_detection_confidence=self.threshold
        )
        self.model.__enter__()
        self._logger.info(f"Loaded Model successfully")

    def close(self):
        self.model.__exit__()

    def predict(self, image: np.asarray):
        """Detect faces in the image

        Args:
            image (np.asarray): input image

        Returns:
            tf.Tensor: Model output
        """
        results = self.model.process(image)
        return results

    @log_time
    def process(self, ctx: Dict[str, Any]) -> Any:
        """Detects face in the image

        Args:
            ctx (Dict[str, Any]): ctx object passed between nodes

        Returns:
            Any: ctx after adding output of this node
        """
        image: np.asarray = ctx.get("image")
        pre_image = self.preprocess(image)
        output = self.predict(pre_image)
        detections, face_crops = self.postprocess(
            image,
            output,
        )
        return {"detections": detections, "face_crops": face_crops, **ctx}

    @log_time
    def process_batch(self, ctx: Dict[str, Any]) -> Any:
        images: List[np.asarray] = ctx.get("image")
        # process batch
        detections = []
        face_crops = []
        for image in images:
            pre_image = self.preprocess(image)
            output = self.predict(pre_image)
            detection, face_crop = self.postprocess(
                image,
                output
            )
            detections.append(detection)
            face_crops.append(face_crop)
        return {"detections": detections, "face_crops": face_crops, **ctx}

    def preprocess(self, image: np.asarray):
        """
        preprocess image before passing to model
        Args:
            image (np.asarray): [description]
            pad (bool): pad the image

        Returns:
            [type]: [description]
        """
        return image[...,::-1]

    def _normalized_to_pixel_coordinates(self, normalized_x: float, normalized_y: float, image_width: int,image_height: int):
        """Converts normalized value pair to pixel coordinates."""

        # Checks if the float value is between 0 and 1.
        def is_valid_normalized_value(value: float) -> bool:
            return (value > 0 or math.isclose(0, value)) and (value < 1 or
                                                            math.isclose(1, value))

        if not (is_valid_normalized_value(normalized_x) and
                is_valid_normalized_value(normalized_y)):
            # TODO: Draw coordinates even if it's outside of the image bounds.
            return None
        x_px = min(math.floor(normalized_x * image_width), image_width - 1)
        y_px = min(math.floor(normalized_y * image_height), image_height - 1)
        return x_px, y_px

    def postprocess(self, image: np.asarray, model_output: Any):
        """
        Post Process detections

        Args:
            image (np.asarray): orignal image
            model_output (Any): raw model output
            im_info ([type]): image info for postprocessing generated by preprocessing
            im_scale ([type]): image scale to rescale detections, generated by preprocessing

        Returns:
            List[Any]: detections and face_crops
        """

        # image to uint8
        image = image.astype("uint8")

        if not model_output.detections:
            detections = []
            face_crops = []
            if self.no_detection == "face":
                detections.append({"face": [0, 0, image.shape[1], image.shape[0]]})
                face_crops.append(image)
            return detections, face_crops

        annotated_image = image.copy()

        
        for detection in model_output.detections:
            self.mp_drawing.draw_detection(annotated_image, detection)
        detections = []
        face_crops = []

        image_rows, image_cols, _ = image.shape
        for detection in model_output.detections:
            relative_bounding_box = detection.location_data.relative_bounding_box
            p1 = self._normalized_to_pixel_coordinates(
                relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,
                image_rows)
            p2 = self._normalized_to_pixel_coordinates(
                relative_bounding_box.xmin + relative_bounding_box.width,
                relative_bounding_box.ymin + +relative_bounding_box.height, image_cols,
                image_rows)

            if p1 is not None and p2 is not None:
                x1,y1 = p1
                x2, y2 = p2
                bbox = list(map(int, [x1, y1, x2, y2]))
            else:
                continue
            
            # add 5% margin
            # reduce width increse height
            x1,y1,x2,y2 = bbox
            m_x, m_y = int((0.16 * (x2-x1))//2) , int((0.08 * (y2-y1))//2)
            x1,y1,x2,y2 = x1+m_x, y1-m_y, x2 - m_x, y2+m_y 

            face_crop = image[y1:y2,x1:x2]

            kps = detection.location_data.relative_keypoints
            def get_kp(idx):
                return self._normalized_to_pixel_coordinates(kps[idx].x, kps[idx].y, image_cols,image_rows)
            keypoints = {}
            keypoints["right_eye"] = get_kp(0)
            keypoints["left_eye"]= get_kp(1)
            keypoints["nose"]= get_kp(2)
            keypoints["mouth"]= get_kp(3)
            keypoints["right_face"]= get_kp(4)
            keypoints["left_face"]= get_kp(5)
            

            detections.append({"face":[x1,y1,x2,y2],"landmarks":keypoints})
            face_crops.append(face_crop)
        return detections, face_crops
